
# Deep Learning Architectures for Fashion-MNIST

Welcome to the **Deep Learning Architectures for Fashion-MNIST** repository! This project showcases the evolution of deep learning models, starting from basic Multilayer Perceptrons (MLPs) to advanced architectures like LeNet and transfer learning with pre-trained models. The repository is designed to demonstrate a solid understanding of foundational and advanced concepts in deep learning, paired with practical implementation.

---

## üöÄ Highlights of the Repository

1. **From Scratch to Advanced Architectures**  
   - Begin with a **Multilayer Perceptron (MLP)** built entirely from scratch.
   - Progress to **LeNet**, one of the earliest Convolutional Neural Network (CNN) architectures.
   - Experiment with architectural improvements to LeNet.
   - Implement **transfer learning** using pre-trained models like ResNet and VGG.

2. **Fashion-MNIST Dataset**  
   - A widely used dataset for benchmarking image classification models.  
   - Contains 60,000 training images and 10,000 testing images, each belonging to one of 10 categories like T-shirts, trousers, dresses, and more.

3. **Performance Comparisons**  
   - Evaluate models using key metrics such as accuracy, precision, recall, and F1-score.
   - Visualize training progress with loss and accuracy graphs.
   - Compare the strengths and weaknesses of different architectures.

4. **Reproducible Code**  
   - Clean, well-documented, and modular code ensures easy reproducibility.
   - GPU support for faster training.

---

## üìÅ Repository Structure

- **`MLP_from_scratch.ipynb`**  
   - Implements a basic MLP for Fashion-MNIST.  
   - Covers data preprocessing, training, and evaluation.  
   - Demonstrates hyperparameter tuning and visualizes model performance.

- **`Lenet_and_transfer_learning.ipynb`**  
   - Replicates **LeNet**, the pioneering CNN architecture, for Fashion-MNIST classification.  
   - Explores architectural improvements to boost performance.  
   - Implements **transfer learning** with pre-trained models for enhanced accuracy.  

---

## üß† Key Concepts Covered

1. **Multilayer Perceptrons (MLPs)**  
   - How to implement a simple neural network from scratch.  
   - Insights into activation functions, optimization, and loss calculation.

2. **LeNet Architecture**  
   - Historical significance as one of the earliest CNNs.  
   - Layer-by-layer breakdown of the architecture.

3. **Transfer Learning**  
   - Leverage pre-trained models to reduce training time and improve accuracy.  
   - Fine-tune models like ResNet and VGG for Fashion-MNIST.

4. **Model Evaluation**  
   - In-depth analysis of metrics and common misclassifications.  
   - Visualization of performance trends across architectures.

---

## üîç Visuals and Insights

- **Dataset Visualization**  
   - See sample images with corresponding labels to get a feel for the dataset.

- **Training Visuals**  
   - Monitor training and validation loss/accuracy across epochs.
   - Understand the impact of architectural changes on model performance.

---

## üìö Learning Objectives

By exploring this repository, you will:
- Understand the progression from basic to advanced deep learning architectures.
- Learn how to implement and evaluate neural networks for image classification.
- Discover the power of transfer learning in modern machine learning workflows.

---

## ü§î Why This Project Matters?

This project highlights both the theoretical and practical aspects of deep learning. It shows how foundational concepts evolve into cutting-edge techniques, making it an excellent showcase of skills for any machine learning enthusiast or professional.

---

## ‚ö° Quick Start

1. Clone the repository:
   ```bash
   git clone https://github.com/Mister-kaushalam/MLP-to-LeNet-Architectures-Explored.git
   cd MLP-to-LeNet-Architectures-Explored
   ```

2. Install the required dependencies mentioned in the notebook

3. Run the notebooks:
   - Start with `MLP_Fashion_MNIST_implementation.ipynb` for foundational concepts.
   - Progress to `Fashion_MNIST_LeNet_and_Transfer.ipynb` for advanced architectures.

---

## üìú Acknowledgments

- The **Fashion-MNIST dataset** by Zalando for providing a great dataset for image classification.  
- Yann LeCun for the original **LeNet architecture**, a cornerstone in deep learning.  
- PyTorch and Torchvision for making deep learning accessible.

---

## üìù Future Directions

- Extend the project to other datasets like CIFAR-10 or ImageNet.  
- Experiment with state-of-the-art architectures like Vision Transformers (ViT).  
- Add hyperparameter tuning with frameworks like Optuna or Ray Tune.  

# Author
Author: Kaushal Bhavsar
LinkedIn : https://www.linkedin.com/in/kb07/
Github: Mister-kaushalam
Email - Kaushalbhavsar0007@gmail.com
